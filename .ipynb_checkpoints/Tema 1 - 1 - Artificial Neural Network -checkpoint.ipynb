{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU > CPU (more cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv(\"../datasets/churn/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll not include the columns \"RowNumber, CustomerId, Surname\" (columns 0, 1, 2 starting with the number 0)\n",
    "# Se incluirán los índices del 3 al 12\n",
    "X = dataset.iloc[:, 3:13].values # No toma el último límite (13)\n",
    "y = dataset.iloc[:, 13].values # Variable independiente (Clase binaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Datos Categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a encodear los países para que se muestren cómo números (1,2,3...) en vez de sus nombres\n",
    "labelencoder_X_1 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos la columna \"Geography\" con la posición \"4\" del dataset pero en la posición 1 de \"X\"\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 0 'Female' ... 1 1 101348.88]\n",
      " [608 2 'Female' ... 0 1 112542.58]\n",
      " [502 0 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 0 'Female' ... 0 1 42085.58]\n",
      " [772 1 'Male' ... 1 0 92888.52]\n",
      " [792 0 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X) #0: France, 1: Germany, 2: Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodear columna de Género (posición 2 en array \"X\")\n",
    "labelencoder_X_2 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:,2]) # 0: Mujer, 1: Hombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que no hay un orden categórico entre los paises (Alemania no está más alto que españa, o más bajo o cualquier otro ejemplo con ellos) es que deberemos crear Dummy variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [1]) #Columna 1 de Geography. [1] es el index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\CursoDL\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Anaconda3\\envs\\CursoDL\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X = onehotencoder.fit_transform(X).toarray() # Hará onehotencoder sobre el index indicado arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 619, 0, 42, 2, 0, 1, 1, 1, 101348]\n"
     ]
    }
   ],
   "source": [
    "# Imprimir cantidad de decimales específicos print(np.around(randomArray,3))\n",
    "print([int(x) for x in X[0,:]]) # Primera fila del narray con el país de Francia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que onehotcodea la columna de \"Geography\" y agrega un array en la posición 0 del array donde se encuentra el OneHotEncode realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 608, 0, 41, 1, 83807, 1, 0, 1, 112542]\n",
      "[0, 1, 0, 772, 1, 42, 3, 75075, 2, 1, 0, 92888]\n"
     ]
    }
   ],
   "source": [
    "print([int(x) for x in X[1,:]]) # España\n",
    "print([int(x) for x in X[9998,:]]) # Alemania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Trap\n",
    "\n",
    "* La solución a la **\"Trampa de Variables Ficticias\"** es descartar una de las variables categóricas (o, alternativamente, descartar la constante de intercepción): si hay m número de categorías, use m-1 en el modelo, el valor dejado de lado puede considerarse como \"El valor de referencia\" y los valores de ajuste de las categorías restantes representan el cambio de esta referencia.\n",
    "\n",
    "* Sin embargo, al incluir la variable ficticia en un modelo de regresión, se debe tener cuidado con la trampa de la variable ficticia. La trampa de variables ficticias es un escenario en el que las variables independientes son multicolineales, un escenario en el que dos o más variables están altamente correlacionadas; En términos simples, una variable puede predecirse a partir de las otras.\n",
    "\n",
    "* En nuestro caso eliminaremos la primera columna en la cual si había un \"1\" en ella significaba que el país de la fila era Francia. ¿Qué ocurre al eliminar esta columna? Todas las filas que correspondan a Francia se representarán con \"0 - 0\" en vez de hacerlo con \"1 - 0 - 0\" cuando realizabamos One Hot Encode ya que ahora tenemos una columna menos.\n",
    "\n",
    "* Por lo tanto, para prevenir el *Dummy Variable Trap* eliminamos una columna y los paises quedarían representados de la siguiente manera:\n",
    "\n",
    "\n",
    "    * France:  0 0\n",
    "    * Germany: 1 0\n",
    "    * Spain:   0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomo todas las filas pero guardo desde la columna 1 hasta la última. No se toma en cuenta la columna 0\n",
    "X = X[:, 1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 619, 0, 42, 2, 0, 1, 1, 1, 101348]\n"
     ]
    }
   ],
   "source": [
    "print([int(x) for x in X[0,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% entrenamiento, 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling / Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5698443964785871, 1.7430904917395806, 0.16958176236487257, -1.0916871447067054, -0.4646079607618638, 0.006660987606337193, -1.2157174870472267, 0.8095028981551202, 0.6425949687704583, -1.032270427743097, 1.1064316603959783]\n"
     ]
    }
   ],
   "source": [
    "print([x for x in X_train[0,:]]) # Datos estandarizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Create the ANN (Adding Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se debe iniciarlizar el modelo como una secuencia de layers o como un grafo\n",
    "\n",
    "# Inicializando la ANN creando el modelo que será un modelo de clasificación\n",
    "classifier = Sequential() # Se crea un objeto como una secuencia de capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se deben agregar las capas (layers) a la red comenzando por la layer input y la primera capa oculta\n",
    "\n",
    "# Primer paso de como crear y ejecutar una ANN\n",
    "# Tenemos una clase binaria: un cliente abandona o no el banco\n",
    "# Se utilizará la función de activación Rectificadora para las capas ocultas\n",
    "# Y la función sigmoide para las capas de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definition__: Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "__Type__: Present in *keras.layers.core* module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear la Layer input y la primera Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay distintos métodos para determinar los nodos de las capas ocultas. El usado aquí es (1+11)/2 [Con 11 el número de nodos de entrada]\n",
    "\n",
    "# units (antes llamada output_dim): Cantidad de nodos de la capa oculta\n",
    "# kernel_initializer(antes llamada init): Debemos Inicializar los pesos con valores cercanos a cero por lo que se usa una funcióndistribución uniforme.\n",
    "# ... Los pesos se inicializan de manera aleatoria con pesos cercanos a cero y uniformes entre ellos.\n",
    "# activation: Función de activación de rectificación (relu)\n",
    "# input_dim: Número de nodos en la input layer: 11 (columnas). Como no la red no tiene información de los nodos de las capas\n",
    "# ... al estar recién creándose, debemos especificar, solo en la primera ocasión la cantidad de nodos de la capa de entrada.\n",
    "\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11)) # Agregamos la input layer y la primera capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear las otras capas (Segunda capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar la capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una sola capa de salida, una sola clasificación\n",
    "# Si tenemos más de una clase (categoria) usamos la activación Softmax que es la Sigmoide pero aplicada a más de una clase \n",
    "# ... y se debe especificar que la salida es 3, por ejemplo, en vez de 1.\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de capas en el modelo:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de capas en el modelo: \", len(classifier.layers)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Compile the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: compile(optimizer, loss, metrics=[], sample_weigth_mode=None)\n",
    "\n",
    "Type: Present in keras.models.Sequential module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: fit(x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0, validation_data=None, shuffle=True, class_weigth=None, sample_weigth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 5s 630us/step - loss: 0.4819 - acc: 0.7961\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 4s 440us/step - loss: 0.4295 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 3s 391us/step - loss: 0.4234 - acc: 0.7961\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 4s 476us/step - loss: 0.4190 - acc: 0.8220 1s -\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 4s 453us/step - loss: 0.4166 - acc: 0.8261\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 4s 524us/step - loss: 0.4142 - acc: 0.8291\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 4s 541us/step - loss: 0.4136 - acc: 0.8311\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 5s 607us/step - loss: 0.4122 - acc: 0.8317\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 4s 503us/step - loss: 0.4112 - acc: 0.8316\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 4s 503us/step - loss: 0.4101 - acc: 0.8336\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 4s 480us/step - loss: 0.4093 - acc: 0.8349\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 5s 580us/step - loss: 0.4087 - acc: 0.8342\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 4s 494us/step - loss: 0.4075 - acc: 0.8340\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 4s 480us/step - loss: 0.4071 - acc: 0.8346\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 4s 517us/step - loss: 0.4069 - acc: 0.8331\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 0.4066 - acc: 0.8329\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 5s 563us/step - loss: 0.4059 - acc: 0.8347\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s 473us/step - loss: 0.4059 - acc: 0.8349\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 4s 532us/step - loss: 0.4055 - acc: 0.8340\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 5s 582us/step - loss: 0.4059 - acc: 0.8339\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 4s 545us/step - loss: 0.4047 - acc: 0.8346\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 4s 493us/step - loss: 0.4045 - acc: 0.8335\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 5s 603us/step - loss: 0.4046 - acc: 0.8344\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 4s 557us/step - loss: 0.4039 - acc: 0.8356\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 4s 552us/step - loss: 0.4040 - acc: 0.8332\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 5s 579us/step - loss: 0.4039 - acc: 0.8350 0s - loss: 0.4038 - acc: 0.835\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 5s 599us/step - loss: 0.4033 - acc: 0.8341\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 4s 520us/step - loss: 0.4035 - acc: 0.8345\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 4s 511us/step - loss: 0.4039 - acc: 0.8340\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 5s 584us/step - loss: 0.4033 - acc: 0.8340\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 5s 575us/step - loss: 0.4035 - acc: 0.8336\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 4s 504us/step - loss: 0.4032 - acc: 0.8346\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 4s 530us/step - loss: 0.4031 - acc: 0.8344\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 5s 608us/step - loss: 0.4033 - acc: 0.8346\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 4s 546us/step - loss: 0.4027 - acc: 0.8341\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 4s 535us/step - loss: 0.4031 - acc: 0.8355\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 4s 558us/step - loss: 0.4028 - acc: 0.8349\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 5s 578us/step - loss: 0.4027 - acc: 0.8341\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 4s 524us/step - loss: 0.4026 - acc: 0.8356\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 4s 551us/step - loss: 0.4027 - acc: 0.8340\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 5s 587us/step - loss: 0.4028 - acc: 0.8337\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 5s 586us/step - loss: 0.4020 - acc: 0.8346\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 4s 499us/step - loss: 0.4028 - acc: 0.8339\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 4s 555us/step - loss: 0.4025 - acc: 0.8349\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 5s 634us/step - loss: 0.4026 - acc: 0.8354\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 4s 509us/step - loss: 0.4026 - acc: 0.8326\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 4s 487us/step - loss: 0.4029 - acc: 0.8337\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 4s 531us/step - loss: 0.4029 - acc: 0.8345\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 5s 633us/step - loss: 0.4026 - acc: 0.8351\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 4s 507us/step - loss: 0.4026 - acc: 0.8325\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 4s 516us/step - loss: 0.4022 - acc: 0.8344\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 5s 682us/step - loss: 0.4024 - acc: 0.8349\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 5s 626us/step - loss: 0.4022 - acc: 0.8339\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 5s 661us/step - loss: 0.4020 - acc: 0.8340\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 6s 694us/step - loss: 0.4020 - acc: 0.8349\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 5s 613us/step - loss: 0.4025 - acc: 0.8344\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 4s 547us/step - loss: 0.4022 - acc: 0.8341\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.4017 - acc: 0.8341\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 4s 557us/step - loss: 0.4020 - acc: 0.8335\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 4s 481us/step - loss: 0.4020 - acc: 0.8339\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 4s 499us/step - loss: 0.4019 - acc: 0.8356\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 4s 548us/step - loss: 0.4015 - acc: 0.8350\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 4s 488us/step - loss: 0.4019 - acc: 0.8365\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 4s 502us/step - loss: 0.4018 - acc: 0.8347\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 4s 475us/step - loss: 0.4010 - acc: 0.8347\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 4s 553us/step - loss: 0.4018 - acc: 0.8352\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 4s 486us/step - loss: 0.4017 - acc: 0.8345\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 4s 482us/step - loss: 0.4012 - acc: 0.8332 0s - loss: 0.4005 - acc: 0.833\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4013 - acc: 0.833 - 4s 484us/step - loss: 0.4016 - acc: 0.8336\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 4s 558us/step - loss: 0.4016 - acc: 0.8334\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 4s 479us/step - loss: 0.4014 - acc: 0.8345\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 4s 484us/step - loss: 0.4013 - acc: 0.8349\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 4s 484us/step - loss: 0.4012 - acc: 0.8335\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 5s 569us/step - loss: 0.4010 - acc: 0.8342\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 4s 478us/step - loss: 0.4013 - acc: 0.8340\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 4s 482us/step - loss: 0.4012 - acc: 0.8347\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 4s 526us/step - loss: 0.4009 - acc: 0.8335\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 5s 621us/step - loss: 0.4009 - acc: 0.8347\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 4s 511us/step - loss: 0.4007 - acc: 0.8356\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 4s 523us/step - loss: 0.4015 - acc: 0.8349\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 4s 515us/step - loss: 0.4007 - acc: 0.8339\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 4s 559us/step - loss: 0.4008 - acc: 0.8341\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 4s 493us/step - loss: 0.4009 - acc: 0.8349\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.4012 - acc: 0.8340\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 4s 496us/step - loss: 0.4004 - acc: 0.8356\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 4s 511us/step - loss: 0.4008 - acc: 0.8346\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 4s 479us/step - loss: 0.4003 - acc: 0.8335\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 4s 475us/step - loss: 0.4010 - acc: 0.8349\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 4s 524us/step - loss: 0.4003 - acc: 0.8340\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 4s 552us/step - loss: 0.4009 - acc: 0.8341\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 4s 490us/step - loss: 0.4004 - acc: 0.8344\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 4s 478us/step - loss: 0.4012 - acc: 0.8350\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 4s 560us/step - loss: 0.4010 - acc: 0.8351\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 4s 534us/step - loss: 0.4003 - acc: 0.8346\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 4s 469us/step - loss: 0.4005 - acc: 0.8354\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 4s 464us/step - loss: 0.4007 - acc: 0.8356\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 4s 510us/step - loss: 0.4007 - acc: 0.8332\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 4s 514us/step - loss: 0.4007 - acc: 0.8344\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 4s 510us/step - loss: 0.4005 - acc: 0.8357\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 4s 461us/step - loss: 0.4005 - acc: 0.8331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272350f9b70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora debemos \"fit\" la red neuronal en el set de entrenamiento\n",
    "# Batch Learning\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora debemos probar el set de testing para determinar como clasifica cada uno de los 2000 clientes restantes\n",
    "# Obtendremos la probabilidad de que abandone el banco según los datos ya entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test) # Obtener las probabilidades que se han predecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1808432 ]\n",
      " [0.3079047 ]\n",
      " [0.1778018 ]\n",
      " ...\n",
      " [0.12785552]\n",
      " [0.13103132]\n",
      " [0.0790797 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred) # Devuelve las probabilidades de que el cliente abandone el banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para utilizar la matriz de confusión, no necesitamos la probabilidad de cada cliente de abandono sino que un verdadero \n",
    "# ... o falso si el cliente tiene una alta probabilidad de abandonar o no el banco. Debemos elegir un límite de elegir\n",
    "# ... verdadero o falso según la probabilidad. Se elige un 50% para separar ambos.\n",
    "\n",
    "y_pred = (y_pred > 0.5) # Devuelve un V o F si se cumple o no esa condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1553,   42],\n",
       "       [ 276,  129]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos 1553 + 129 predicciones correctas y 276 + 42 predicciones incorrectas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_test = (1553 + 129) / (2000)\n",
    "accuracy_test = (c_matrix[0][0] + c_matrix[1][1]) / (len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos una precisión de 0.8331 o 83.31% en el conjunto de entrenamiento y un 84.1% en el conjunto de testing. Por lo cual validamos el modelo de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea: Realizar una predicción de una sola observación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework Instruction\n",
    "\n",
    "\n",
    "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
    "\n",
    "   * Geography: France\n",
    "   * Credit Score: 600\n",
    "   * Gender: Male\n",
    "   * Age: 40 years old\n",
    "   * Tenure: 3 years\n",
    "   * Balance: $60000    \n",
    "   * Number of Products: 2\n",
    "    \n",
    "   * Does this customer have a credit card ? Yes\n",
    "   * Is this customer an Active Member: Yes\n",
    "   * Estimated Salary: $50000\n",
    "\n",
    "So should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debemos utilizar un vector horizontal (usar doble [[]]: crea un array de dos dimensiones, matriz, \n",
    "# ... pero solo almacenamos en la primera fila, parentesis de adentro)en donde almacenaremos toda la información que \n",
    "# ...queremos\n",
    "# Ya que nuestro set de entrenamiento está en un escalado distinto (fit.transform) debemos usar lo mismo para este array\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))) # Ponemos el primer valor como \"0.0\" o float para que no nos de un warning. Solo basta con poner un solo float\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction # El cliente no tiene posibilidad de irse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
